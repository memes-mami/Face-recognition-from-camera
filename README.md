# Face-recigocnition-from-camera

Absolutely! Here's the **full `README.md` file**, ready to be saved and used in your project directory.

---

### âœ… Save as: `README.md`

```markdown
# ğŸ§  Face Recognition from Camera

Real-time multi-face recognition system using **YOLO-NAS-M** (from Deci's SuperGradients) for face detection and **ArcFace** (via InsightFace) for high-accuracy face embedding and recognition. Designed for easy video or webcam-based attendance logging and supports log summarization using LLMs like Gemma via Ollama.

---

## ğŸ“¸ Features

| Feature | Description |
|---------|-------------|
| ğŸ¥ Video Mode | Upload a video and get per-face time logs |
| ğŸ“· Live Camera Mode | Recognize and log faces from your webcam |
| â• Register Mode | Add new faces from webcam or video input |
| ğŸ§  YOLO-NAS-M | High-performance, custom-trained face detector |
| ğŸ§¬ ArcFace | Industry-standard face embedding via InsightFace |
| ğŸ“ Auto Logging | Saves all detections and times into `.txt` files |
| ğŸ’¬ LLM Summary | Summarize logs using local LLM (Gemma via Ollama) |

---
## ğŸ—‚ Project Structure



face_recognition_project/
â”œâ”€â”€ app.py                  # ğŸ“± Main Streamlit GUI app
â”œâ”€â”€ utils.py                # ğŸ”§ Core logic for detection, recognition
â”œâ”€â”€ identify.py             # ğŸ§ª Standalone test script for face identification
â”œâ”€â”€ face_data.py            # ğŸ“¦ KnownFace class for loading/saving face embeddings (pickle)
â”œâ”€â”€ register_facesvedio.py  # â• Register faces using video or webcam feed
â”œâ”€â”€ summary.py              # ğŸ§  Log summarization using LLM (Gemma)
â”œâ”€â”€ known_faces.pkl         # ğŸ¤ Serialized face embeddings database
â”œâ”€â”€ video_session_log.txt   # ğŸ“ Log file for video-based detections
â”œâ”€â”€ live_session_log.txt    # ğŸ“ Log file for live webcam detections
â”œâ”€â”€ weights/
â”‚   â””â”€â”€ yolo_nas_m.pt       # ğŸ¯ Offline YOLO-NAS-M weights for face detection

````

---

## ğŸ› ï¸ Setup Instructions

### âœ… Python Version
Use Python **3.10+** with **CUDA GPU** for best performance.

### âœ… Create Virtual Environment

```bash
python -m venv venv
venv\Scripts\activate  # (Windows)
````

### âœ… Install Required Packages

Use `requirements.txt` if available, or manually:

```bash
pip install streamlit==1.34.0 opencv-python==4.11.0.86 torch==2.3.1+cu121 torchvision==0.18.1+cu121 \
super-gradients==3.7.1 insightface==0.7.3 scikit-learn==1.3.2 numpy==1.23.0 pandas==2.3.1 \
onnxruntime==1.15.0 onnxruntime-gpu==1.22.0 requests==2.31.0 matplotlib==3.10.3 tqdm==4.67.1
```

---

## ğŸš€ Running the App

Launch the app with:

```bash
streamlit run app.py
```

Then in the sidebar, select:

* **ğŸ“· Live Camera Mode**
* **ğŸ¥ Video File Mode**
* **â• Register Mode**

---

## ğŸ§¬ Registering Faces

You can register new faces either:

* Through the **app** (Register tab), or
* Using CLI:

```bash
python register_facesvedio.py
```

You'll be prompted to:

* Capture the face from webcam/video
* Enter the person's name
* It will save to `known_faces.pkl`

---

## ğŸ§¾ Attendance Log Summarization (Optional)

To convert raw logs into a friendly summary:

### Step 1: Install and Run Ollama

```bash
ollama run gemma:4b
```

### Step 2: Run the summarizer

```bash
python summary.py
```

It will generate a short summary of `video_session_log.txt` using your local LLM.

---

## âœ… How It Works

1. **YOLO-NAS-M** detects faces in frames (real-time or video)
2. **ArcFace** extracts 512-dimensional facial embeddings
3. **Cosine Similarity** compares to saved embeddings
4. Matches are displayed and detection times logged

---

## ğŸ” Requirements (From Your `pip list`)

Here are the core packages and versions you are using:

| Package         | Version      |
| --------------- | ------------ |
| streamlit       | 1.34.0       |
| opencv-python   | 4.11.0.86    |
| torch           | 2.3.1+cu121  |
| torchvision     | 0.18.1+cu121 |
| super-gradients | 3.7.1        |
| insightface     | 0.7.3        |
| numpy           | 1.23.0       |
| scikit-learn    | 1.3.2        |
| pandas          | 2.3.1        |
| onnxruntime     | 1.15.0       |
| onnxruntime-gpu | 1.22.0       |
| matplotlib      | 3.10.3       |
| requests        | 2.31.0       |
| tqdm            | 4.67.1       |

> These versions were taken from your current environment.

---

## ğŸ“’ Notes

* `known_faces.pkl` must be generated using the `KnownFace` class in `face_data.py`
* If CUDA is not available, InsightFace will use CPU (slower)
* Custom YOLO-NAS-M weights are trained for **1-class (face only)** detection

---

## ğŸ™‹ FAQ

* **Q: Getting `Can't get attribute 'KnownFace'`?**
  â¤ Make sure `face_data.py` exists and `KnownFace` is imported wherever you load `known_faces.pkl`

* **Q: Where are logs saved?**
  â¤ Logs go to `video_session_log.txt` or `live_session_log.txt`

* **Q: How to detect from images instead of video?**
  â¤ Use `identify.py` or write a simple wrapper using `utils.detect_face_yolonas()` and `identify_face()`

---

## ğŸ‘¤ Author

Built with â¤ï¸ by \[Your Name]
ğŸ“¬ Contact: \[[you@example.com](mailto:you@example.com)]

---

## ğŸ“ License

MIT License â€” feel free to use, improve, and share.

```

---

### âœ… Bonus: Want a `requirements.txt` from your environment?

Let me know and Iâ€™ll generate it for you directly from your package list.
```
